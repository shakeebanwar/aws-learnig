Amazone Credential:
u882515@gmail.com

Shaigan Ip:
51.79.51.181

How to Enable Password Authentication in AWS ec2 Instances:

Step 1:
ssh -i "hnh.pem" ubuntu@ec2-3-139-68-29.us-east-2.compute.amazonaws.com

Step 2:
sudo passwd ubuntu(ubuntu is my username)

Step 3:
sudo vim /etc/ssh/sshd_config

*Find the Line containing 'PasswordAuthentication' parameter and change its value from 'no' to 'yes'

*PasswordAuthentication yes

*If you want to set up 'root' login, find  'PermitRootLogin' parameter and change its value from 'prohibit-password' to 'yes'

*PermitRootLogin yes


Step 4:
service ssh restart

Step 5:
ssh ubuntu@ec2-3-139-68-29.us-east-2.compute.amazonaws.com


Root User:
ssh ubuntu@3.143.108.49

Normal User:
ssh shakeeb@3.143.108.49


Git Installation:
sudo apt install git-all

Docker Installation:

1.sudo apt-get update
2.sudo apt-get install \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg-agent \
    software-properties-common

3.curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
4.sudo apt-get install docker-ce docker-ce-cli containerd.io
5.apt-cache madison docker-ce
6.sudo apt-get install docker-ce docker-ce-cli containerd.io
7.sudo apt install docker.io
8.sudo apt install docker-compose



Docker crash course:
https://collabnix.com/docker-cheatsheet

-d (background)
-p (port mapping)
1.docker run -d -p 80:80 nginx (nginx ak image ha image ka matlab ha wo sari info jo ak container ko run karna ka liya chaye)

2.ufw allow 5000 (apni machine ma port ko allow kar sakta ho)
3.docker system prune

4.docker cp containerid:filename machinelocation (for e.g docker cp 1f:1.txt shakeeb.txt) yaha honga ya container ka andar sa 1.txt ko copy karaga aur shakeeb.txt ma daal daga)

5.local machine sa agar container ka andar koi cheeze copy karni ho tu (docker cp 1.txt containerid:shakeeb.txt)

6.docker commit containerid reponame:6:7(docker commit 1fgf shakeeb/nginx:6.7) 
  
  is command sa jo bi humna container ma changes kiya honga usko as a image save kardaga



After deploying the docker container Ec2 Instance:
Allow the port to edit the security group for Example if your docker container run 8005 so edit edit the security group tcp 8005 


Bind a Domain:


sudo vim /etc/nginx/sites-available/clearpricing.ga
sudo ln -s /etc/nginx/sites-available/clearpricing.ga /etc/nginx/sites-enabled
sudo systemctl restart nginx



Create a Reverse Proxy using Ngnix:

server {
    listen 80;
    server_name www.clearpricing.ga;

     proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header Host $host;
    proxy_set_header X-Forwarded-Proto $scheme;


    location / {

        proxy_pass http://18.119.12.94:8005;
    }
}

server {
    listen 80;
    server_name surfeye.video www.surfeye.video;

    location / {

        proxy_pass http://18.157.161.94:8005;
    }

     location /static/ {
      alias /hnh/seawaves/staticfiles/;
    }
  
}

Create a Reverse Proxy using Apache:                                                                    
                                                                                              
<VirtualHost *:80>
 ServerName shaigansehat.com
 ServerAlias www.shaigansehat.com
 ProxyPass / http://51.79.51.181:8000/
</VirtualHost>



Transfer local machine file to remote server:
scp -r ./build/* username@server_ip:/var/www/your_domain/html
mkvirtualenv -p $(pyenv which python) myenv


How i host react using nginix
----------------------------------
1.first upload your build folder.
2.create a reverse proxy using nginx

vim /etc/nginx/sites-enabled/your_domain
server {mkvirtualenv -p $(pyenv which python) myenv

        listen 80;
        listen [::]:80;

        root /hnh/deploy/build;
        index index.html index.htm index.nginx-debian.html;

        server_name clearpricing.ml www.clearpricing.ml;

        location / {
                try_files $uri $uri/ =404;
        }
}


####add htc access 


server {
        listen 80;
        listen [::]:80;
        root /hnh/testing/testbuild/build;mkvirtualenv -p $(pyenv which python) myenv

        index index.html index.htm index.nginx-debian.html;

        server_name cynotech.ga www.cynotech.ga;

        location ~* \.(?:manifest|appcache|html?|xml|json)$ {
    expires -1;
    # access_log logs/static.log; # I don't usually include a static log
  }

  location ~* \.(?:css|js)$ {
    try_files $uri =404;
    expires 1y;
    access_log off;
    add_header Cache-Control "public";
  }

  # Any route containing a file extension (e.g. /devicesfile.js)
  location ~ ^.+\..+$ {
    try_files $uri =404;
  }

  # Any route that doesn't have a file extension (e.g. /devices)
  location / {
    try_files $uri $uri/ /index.html;
  }
}


##Updated version:
server {
        listen 80;
        listen [::]:80;

        root /hnh/deploy/build;
        index index.html index.htm index.nginx-debian.html;

        server_name clearpricing.ml www.clearpricing.ml;

     
        
        location / { try_files $uri /index.html; }
}



3.systemctl restart nginx
-------------------------------------------

How i ssl your domain:
-------------------------------------------
1.sudo apt install certbot python3-certbot-nginx
2.create a proxy file verify the syntax of your configuration:
    * sudo nginx -t
    
3.Reload Nginx to load the new configuration:
    * sudo systemctl reload nginx
    
4.To additionally let in HTTPS traffic, allow the Nginx Full profile and delete the redundant Nginx HTTP profile allowance:
    *sudo ufw allow 'Nginx Full'
    *sudo ufw delete allow 'Nginx HTTP'
    *sudo ufw status
    
    
5.Obtaining an SSL Certificate:
 *sudo certbot --nginx -d example.com -d www.example.com
 
6.Verifying Certbot Auto-Renewal:
    *sudo systemctl status certbot.timer
    *To test the renewal process, you can do a dry run with certbot:
        *sudo certbot renew --dry-run
-------------------------------------------


How i Excess gunicorn server inside the docker using nginx:
1.sudo vim /etc/nginx/sites-available/ngnixguni
2.  server {
    listen 80;
    server_name techbullet.ga www.techbullet.ga;

    location = /favicon.ico { access_log off; log_not_found off; }
    location /static/ {
        root /hnh/ngnixtest/testing-nginx;
    }

    location /upload/ {
      root /hnh/ngnixtest/testing-nginx;
    }

    location / {
      proxy_pass http://3.143.108.49:8004;
    }
}


3.sudo ln -s /etc/nginx/sites-available/ngnixguni /etc/nginx/sites-enabled/
4.ssl(sudo certbot --nginx -d techbullet.ga -d www.techbullet.ga)
5.systemctl restart nginx






##########################If your root or other user password is not update so try this##################################

chattr -i /etc/gshadow
chattr -i /etc/group
chattr -ai /etc/shadow
chattr -ai /etc/passwd



##################################################Django channels##############################################################
Requirements:

Django==3.2.6
channels
channels_redis
Twisted[tls,http2]

Deployement:
we need a Asynchronous web server for deployment like daphne

docker-compose file:

version: "3.7"
services:
  
  redis:
    restart: always
    image: redis:latest
    ports:
      - "6379:6379"
    volumes:
      - ./redisdata:/data
        proxy_redirect off;
        proxy_pass http://18.119.140.171:8005;
    }
    
    
*reload the ngnix server
*your ssl private key and certification file is present at this location  /etc/letsencrypt/live




#############How i increase the file uploading size in nginx#########################


sudo nano /etc/nginx/nginx.conf
http {
    # [...]
    client_max_body_size 100m;  //add only this line 
    # [...]
}

sudo systemctl restart nginx



######################how to install mysql client ubuntu###########################


1.sudo apt install python3-dev build-essential
2.sudo apt install libssl1.1
3.sudo apt install libssl1.1=1.1.1f-1ubuntu2
4.sudo apt install libssl-dev
5.sudo apt install libmysqlclient-dev
6.pip3 install mysqlclient


####How i use mysql outside the docker container####


docker run -p 3307:3306 --name my-mysql -e MYSQL_ROOT_PASSWORD=root -d mysql/mysql-server:latest
docker exec -it containerid bash
mysql -u root -p
enter the password root
select user,host from mysql.user;
update mysql.user set host='%' where user='root';
flush privileges;
create database clearcost;

*configure phpmyadmin and connect to mysql
    docker run --name dev-phpmyadmin -d --link my-mysql:db -p 7098:80 phpmyadmin/phpmyadmin
      
     DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.mysql',
        'NAME': 'clearcost',
        'USER': 'root',
        'PASSWORD': 'root',
        'HOST': '192.168.0.178',
        'PORT': 3307,
        
    }
}



#####################################          Move folder/file from local machine to docker container   ###########################################


docker cp foo.txt container_id:/foo.txt


####################For the created containers use docker update to update restart policy.#######################
docker update --restart=always 0576df221c0b


###Restart container using docker-compose file###################
version: "3.7"
services:
  web:
    build: .
    command: python manage.py runserver 0.0.0.0:8000
    volumes:
      - .:/code
    ports:
      - "8005:8000"
    restart: always





###Restart the all the docker container#########
docker restart $(docker ps -q)


########Remove all the none tag images#############
docker rmi $(docker images --filter "dangling=true" -q --no-trunc)


#### Map the current folder outside the container#######################

version: "3.7"
services:
  web:
    build: .
    command: python manage.py runserver 0.0.0.0:8000
    volumes:  
      - .:/code
    ports:
      - "8005:8000"
      
      
*The volumes tag is a simple saying: "Hey, map the current folder outside the container (the dot) to the working directory inside the container".



#############################Use Postgre outside the docker########################################################


version: '3.7'
services:
    postgres:
        image: postgres
        restart: always
        expose:
          - "5432"
        ports:
          - 5432:5432
        user: postgres  //this is very important
        environment:
          - POSTGRES_DB=postgres
          - POSTGRES_USER=postgres
          - POSTGRES_PASSWORD=postgres
          - POSTGRES_HOST=127.0.0.1
        


#######################################################################



#######################################Auto deployment github##############


mkdir backrepo && cd backrepo
mkdir site.git && cd site.git
git init --bare
cd hooks
vim post-receive
git --work-tree=/hnh/backend/email-sender --git-dir=/hnh/backrepo/site.git checkout -f
chmod +x post-receive
git remote add beta ssh://user@mydomain.com/var/repo/beta.git



###########################################################################
Nginx Load balancing using round robin


upstream endpoint1 {
 server 18.119.140.171:8005;
 server 18.119.140.171:8006;



}
server {
    listen 80;
    server_name beta.jawadsheikh.ml;

    location / {

        proxy_pass http://endpoint1;
    }
}


Nginx Load balancing using wighted approach

upstream endpoint1 {
 server 18.119.140.171:8005;  ##means weight=1
 server 18.119.140.171:8006 weight=2; #means ya server zada powerful ha ya zada request handle karaga weight=2 means 2 bar is per request aye phr 1 bar weight=1 wala pa jaye gi:wq
 



}
server {
    listen 80;
    server_name beta.jawadsheikh.ml;

    location / {

        proxy_pass http://endpoint1;
    }
}


Nginx Load balancing using least connection

upstream endpoint1 {
  least_conn;
  server 18.119.140.171:8005; 
  server 18.119.140.171:8006; 



}
server {
    listen 80;
    server_name beta.jawadsheikh.ml;

    location / {

        proxy_pass http://endpoint1;
    }
}



###########################################################################
How i Increase ssh timeout

ssh -o ServerAliveInterval=300 root@shakeeb.ml

#############################################################################





###Docker swarm installation #############################################



Docker Swarm:


Create a virtual machine:
 docker-machine create --driver virtualbox machine-name

Check no of macine:
 docker-machine ls

Enter into specific machine:
 docker-machine ssh machine-name



 Create a manager:

 1.Enter in to the machine using docker-machine ssh machine-name
 2.docker swarm init --advertise-addr ip-address


JOIN A WORKER:
when create a manager docker swarm produce a token this token is used to join a manager
for example my join command is 

docker swarm join --token SWMTKN-1-4wdsjzm0myc14jqiwptcpog4wfgzht1wyq8p490063mv00xan4-0puuyjguf2qwsvllv0mppuc4r 192.168.99.101:2377


check no of nodes:
 docker node ls
 * this command is only run in manager node


Manage Join Token:
docker swarm join-token manager //if worker so this token is only used for join a worker

The output of this command is
    docker swarm join --token SWMTKN-1-4wdsjzm0myc14jqiwptcpog4wfgzht1wyq8p490063mv00xan4-5ecmnybvz9f13jkldxh1ej3o2 192.168.99.101:2377




Inspect a node:
   Display a detailed information about nodes

   docker node inspect manager1


Promote a node:
    docker node promote worker

Demote a node
    docker node demote worker

information about Docker
    docker info


Types of services in docker swarm:
1.Replicated.
2.Global.

In dono ma jo major difference ha wo ya ha ka Global services all nodes 
pa run karti ha jb ka Replicated Sirf jitna nodes hum define karga sirf 
uspa hi run karagi.

Create a Replicated services:
    docker service create --replicas 4 --name web1 nginx

    *docker service ls (list of services)
    *docker service ps web1 (web1 is a service name)


Scale up your service:
    docker service scale web1=7

Stop service:
    docker service scale web1=0

Update service with a specific version:
    docker service update web1:version
    
    

Deploy a container using docker swarm
1.Craete a docker-compose.yml:


version: '3.7'

services:
  nodejs:
    build:
      context: .
      dockerfile: Dockerfile
    image: sample_app:v1
    restart: unless-stopped
    #env_file: .env
    environment:
      - NODE_ENV=test
    ports:
      - "8080:8080"
    deploy:
     replicas: 4
     restart_policy:
       max_attempts: 3
       condition: on-failure       
     update_config:
       parallelism: 3
       delay: 10s

  proxy:
      build:
        context: .
        dockerfile: Dockerfile.nginx
      image: nginx_proxy:v1
      ports:
        - 81:80
      depends_on:
        - nodeapp
      deploy:
        placement:
          constraints: [node.role == manager]
      depends_on:
        - nodejs









2.docker-compose build --no-cache
3.docker stack deploy -c docker-compose.yml pandaswarm
4.docker service update --force pandaswarm_web (when something change in your application)
 
 

##########################################################################

Install Docker in Aws Ami:

sudo yum update -y
sudo amazon-linux-extras install docker
sudo yum install docker
sudo service docker start
sudo usermod -a -G docker ec2-user
sudo curl -L https://github.com/docker/compose/releases/download/1.21.0/docker-compose-`uname -s`-`uname -m` | sudo tee /usr/local/bin/docker-compose > /dev/null
sudo chmod +x /usr/local/bin/docker-compose
ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
docker-compose --version


Install Nginx Aws Ami:

https://www.nginx.com/resources/wiki/start/topics/tutorials/install/

1.vim /etc/yum.repos.d/nginx.repo
2.paste the following content:

    [nginx]
    name=nginx repo
    baseurl=https://nginx.org/packages/centos/7/$basearch/
    gpgcheck=0
    enabled=1


3.yum update
4.yum install nginx
5.service nginx start


Installation of certbot Aws Ami:


sudo yum update
sudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
sudo yum-config-manager --enable epel
sudo yum install certbot python3-certbot-nginx
certbot --version







Check which service use port 80:

1.netstat -lntp | grep 80

How i kill service running in port 80:

2.sudo kill $(sudo netstat -anp | awk '/ LISTEN / {if($4 ~ ":80$") { gsub("/.*","",$7); print $7; exit } }')



###########################################################################


Serve static files using docker nginx:

Install Nginx:
docker pull nginx

Then:
 docker run -d -p 8000:80 -v /Users/admin/Desktop/aws:/usr/share/nginx/html --name my-nginx nginx


#############################################################################
Create a Reverse Proxy inside the docker container
Install Nginx:
docker pull nginx

Run the Nginx:
docker run -d -p 80:80 nginx

Go inside the Container:
docker exec -it containerid bash

Commands:
1.cd /etc/nginx/conf.d
2.delete the default.conf
3.create two folders: sites-available and sites-enabled.
4.go to the sites-enabled and create a reverse proxy file
5.go to the file nginx.conf and change include /etc/nginx/conf.d/*.conf; to include /etc/nginx/conf.d/sites-enabled/*.conf;
6.nginx -s reload




#############################################################################
Block Iframe

1.open the reverse proxy file for e.g vim /etc/nginx/sites-enabled/myfile
2.add these line add_header X-Frame-Options "DENY";


#############################################################################


Larvel deployment:

https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-laravel-with-nginx-on-ubuntu-20-04

Step1:
Install php or update your older php version:
 https://devanswers.co/how-to-upgrade-from-php-7-x-to-php-8-on-ubuntu-apache/

1.To uninstall PHP 7.x and all of its extensions, run the command below. Press y and ENTER when prompted.
    sudo apt-get purge php7.*

2.After uninstalling packages from Linux, it’s advised to run these two commands.
    sudo apt-get autoclean
    sudo apt-get autoremove

3.Install PHP 8.
   sudo add-apt-repository ppa:ondrej/php
   sudo apt-get update
   sudo apt-get install php8.0

   
4.Install PHP 8 Extensions:
    sudo apt install php-mbstring php-xml php-bcmath
    sudo apt-get install php8.0-pdo-mysql
    sudo apt install php-fpm

5.Install php Composer:
  sudo apt install composer


6.Install composer dependencies:
 composer install --prefer-dist


7.Run these commands to create the tables within the defined database and populate seed data:
 php artisan migrate --seed
  
8.storage permission:
 chmod -R gu+w storage
 chmod -R guo+w storage
 php artisan cache:clear




9.Setting Up Nginx: 
 it’s not a recommended practice for web servers that are open to the public internet. We’ll move the application folder to /var/www, which is the usual location for web applications running on Nginx.


 sudo mv ~/yourproject /var/www/directoryname


 Now we need to give the web server user write access to the storage and cache folders, where Laravel stores application-generated files:

 sudo chown -R www-data.www-data /var/www/travellist/storage
 sudo chown -R www-data.www-data /var/www/travellist/bootstrap/cache


server {


    listen 80;
    server_name localhost;
    root /home/shakeeb/Desktop/LARVEL/Plating/public;

    add_header X-Frame-Options "SAMEORIGIN";
    add_header X-XSS-Protection "1; mode=block";
    add_header X-Content-Type-Options "nosniff";

    index index.html index.htm index.php;

    charset utf-8;

    location / {
        try_files $uri $uri/ /index.php?$query_string;
    }

    location = /favicon.ico { access_log off; log_not_found off; }
    location = /robots.txt  { access_log off; log_not_found off; }

    error_page 404 /index.php;

    location ~ \.php$ {
        fastcgi_pass unix:/var/run/php/php8.1-fpm.sock;
        fastcgi_index index.php;
        fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;
        include fastcgi_params;
    }

    location ~ /\.(?!well-known).* {
        deny all;
    }
}



service nginx restart



###################################################### Introduction to kubernetes. #####################################################



Kubernetes:

kubernetes is a container  orchestration solution.orchestration means jb ak bar apki image create hogaye for e.g docker ka through tu ap usko high available kasa banaye ga,ya loadbalancing aur auto scaling kasa karaga.

kubernetes is a master slave architecture.kubernetes ka sab sa bara advantage ya ha isko use kar ka ap easily apni application ko roleup aur roleback kar sakta ha for e.g apki application ka new version 2.0 realease hoa aur usma koi issue agaya tu hum easily roleback kar ka 1.0 version pa asakta ha.

Features of kubernetes:
1.Automatic Binpacking:
    jb bi hum apni application ko deploy karta ha container ki form ma tu wo container automatically 
    correct resource ko khud  allocate karla.


2.loadbalancing:
 means jb apki application pa zada load ana ki waja sa apki ak node band hojae tu traffic dosra node pa shift hojae.


3.storage orchestration:
 kubernetes hum different types of storage solution use kar sakta ha.


4.Self Healing:
  Iska simple matlab kubernetes ma ya Feature ha ka wo  apna dedicated resource ko excess kara aur agar koi node down hojae tu uski jagha dosri node ko available karwaye.


5.Secrete and Configuration managment:
  kubernetes ma buildin machanism hota ha Secrete store karna ka liya agr ap koi external tool use nhi karna chahta tu iska build in Feature use kar sakta ha apni keys ko encrpt karna ka liya.ya apki keys ko base64 ma convert karta ha.

6.Batch Execution:
  jb bi hum kubernetes run karta ha tu job background ma run karti ha ishi tarha sa hum multiple jobs ko background ma run kar sakta ha.means sequential batch managment.

7.Horizontal Scaling:
  kubernetes world ma fundamental unit ko pods bolta ha .kubernetes ma containers khud sa involved nhi karta  containers humesha pods ka andar consine hota ha . kubernetes ka architecture ma hum apna pods ko Horizontal scale kar sakta ha . Horizontal scaling ka matlab ya ha ka hum new pord apni requirements ka according create kar sakta ha.


8.Automatic Rollbacks and roleout:

  kubernetes ka sab sa bara advantage ya ha isko use kar ka ap easily apni application ko roleup aur roleback kar sakta ha for e.g apki application ka new version 2.0 realease hoa aur usma koi issue agaya tu hum easily roleback kar ka 1.0 version pa asakta ha.



Few Myths About kubernetes:
  1.Docker is container solution and kubernetes is a orchestration solution.  
  2.Docker ko use kar ka hum images ko create karta ha aur images hi container ma convert hota ha. kubernetes ko use kar ka hum images ko create nhi kar sakta.



Kubernetes vs Docker swarm:
1.Both are container orchestration solution.
2.Dono ma fark ya ha ka agar apna apni appplication ko docker ki help sa containerize kiya tu hi ap docker swarm use kar sakta ho.jb ka ap kubernetes kisi bi container platform ka liya use kar sakta ho.

3.Docker swarm itna zada scalable nhi ha kubernetes ka moqabala ma.
4.Docker swarm ma built in loadbalancing technique hoti ha . jb ka kubernetes ma apko enable karni parhti ha.

5.Docker swarm ki update itni zada clean nhi ha.
6.Docker swarm ma container volume ko ap container sa dosra container ma share nhi kar sakta.jb ka kubernetes ma ap isko achieve kar sakta ho.

7.kubernetes ma inbuilt logging and monitoring tool ha jb ka docker swarm ma apko 3rd party tool use karna parha ga.



What is master?
Master controls the cluster and the nodes init.

What is node?
 nodes host the containers inside them. containers are inside separate pods


What is PODS?
  pods are logical collection of containers which need to interact with each other for an application


############################################ Cloudfront ###############################################################################################

Cloudfront:
Cloudfront is just a cdn(Content delivery network) service for aws.cdn means asi service jiski edge service all over the world ha edge location means datacenter.

################################################Push image to docker Hub################################################################################


docker tag firstimage YOUR_DOCKERHUB_NAME/firstimage
docker push YOUR_DOCKERHUB_NAME/firstimage


##########################################Docker ssh configuration setting###############################################
1.Create a Dockerfile and paste the below code


FROM ubuntu:16.04

RUN apt-get update && apt-get install -y openssh-server
RUN mkdir /var/run/sshd
RUN echo 'root:mypassword' | chpasswd
RUN sed -i 's/PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config
RUN sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd
EXPOSE 22
CMD ["/usr/sbin/sshd", "-D"]

2.Building the docker Image
sudo docker build -t sshd_tagged_image .

3.Run the image as a container

# Running the container using the newly built image
docker run -d -P --name test_sshd_container sshd_tagged_image



4.Run docker port to verify SSH connectivity between the Docker host and the container. The docker port command list’s the port mappings or a specific mapping for the container.

sudo docker port test_sshd_container


5.Next, find the IP address of the container. To do that, run the docker inspect command. The docker inspect command queries Docker information and renders the results in JSON array using a format parameter.

6.Finally, now that you have the IP address to SSH to, try to SSH to the container, and it should work!

ssh root@Ip-Address-of-the-container //password is mypassword



###################################How to transferfile from one system to another using scp#############################
1.sudo apt-get install scp

Transfer local to remote server

2.scp filename root@api.libraa.ml:/hnh   //for file
3.scp -r foldername root@api.libraa.ml:/hnh   //for folder

Transfer remote to local

scp root@api.libraa.ml:/remotelocation /localsystemlocation





Use whole sytem vpn:
1.apt-update
2.apt-upgrade
3.apt install tor
4.go to Desktop
5.git clone https://github.com/brainfucksec/kalitorify
6.cd kalitorify
7.make install
8.reboot

stop Vpn
sudo kalitorify -c

start vpn
sudo kalitorify -t





########Load Balancing##################

https://www.youtube.com/watch?v=JQP96EjRM98



###############Sockets reverse proxy#######


http {
  server {
    listen 80;
    server_name example.com;

    location / {
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header Host $host;

      proxy_pass http://localhost:3000;

      proxy_http_version 1.1;
      proxy_set_header Upgrade $http_upgrade;
      proxy_set_header Connection "upgrade";
    }
  }
}



#############################################When Accidently push large file to the github########################################################

git filter-branch --force --index-filter 'git rm --cached --ignore-unmatch PATH-TO-YOUR-FILE' --prune-empty --tag-name-filter cat -- --all



########################################### Resize all images using ubuntu ########################################################################
Modify images using ubuntu:

mogrify -resize 384x384! *.png


################################Run mongodb using docker#####################################33
docker run -d \
  --name my-mongodb \
  -p 27017:27017 \
  -e MONGO_INITDB_DATABASE=neuro-gpt \
  -e DATASTORE_HOST=localhost \
  -e DATASTORE_PORT=27017 \
  -e DATASTORE_TIMEOUT=500 \
  mongo


###############################web sockets nginx configuration############################################
server {
    listen 80;
    server_name api.billionaire.devssh.xyz;

    location / {
        proxy_pass http://localhost:9001;  # Assuming FastAPI is running on localhost:9001
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
    }

    listen 443 ssl; # managed by Certbot
    ssl_certificate /etc/letsencrypt/live/api.billionaire.devssh.xyz/fullchain.pem; # managed by Certbot
    ssl_certificate_key /etc/letsencrypt/live/api.billionaire.devssh.xyz/privkey.pem; # managed by Certbot
    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot
    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot

}
##################################when external drive is not excess in a ubuntu########################
sudo ntfsfix /dev/sda2


###############################Crontab  ###################################################################
Runing python script with a virtualenv :
* * * * * cd /hnh/apple_realtime_google_sheet && /hnh/apple_realtime_google_sheet/apple_ratios/bin/python /hnh/apple_realtime_google_sheet/main.py >>/hnh/apple_realtime_google_sheet/check.log 2>&1


###############################How i login your server without password  ###################################################################
local system
1.ssh-keygen
2.cat ~/.ssh/id_rsa.pub

live server:
1.echo "your-copied-public-key" >> ~/.ssh/authorized_keys
2.chmod 600 ~/.ssh/authorized_keys


############################################How i configure pyenv#################################################
1.sudo apt update
sudo apt install -y make build-essential libssl-dev zlib1g-dev \
libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm \
libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev \
liblzma-dev git

2.curl https://pyenv.run | bash
3.Add these lines in to ~/.bashrc

export PATH="$HOME/.pyenv/bin:$PATH"
eval "$(pyenv init --path)"
eval "$(pyenv init -)"
eval "$(pyenv virtualenv-init -)"


4.source ~/.bashrc

5.pyenv versions
6.pyenv install 3.10.5
7.pyenv global 3.10.5


now,
mkvirtualenv -p $(pyenv which python) myenv


################################# HOW TO CREATE ERD IN A DJANGO #################################################################
pip install django-extensions
sudo apt-get install graphviz  # Ubuntu/Debian systems ke liye

INSTALLED_APPS = [
    # other apps
    'django_extensions',
]

python manage.py graph_models -a -o my_project_erd.svg

IF FACE ERROR:
CommandError: Neither pygraphviz nor pydotplus could be found to generate the image. To generate text output, use the --json or --dot options.

Follow steps for removig error
sudo apt-get install graphviz libgraphviz-dev
pip install pygraphviz

Now run,
python manage.py graph_models -a -o my_project_erd.svg




################## How i setup your own github server ##############################
sudo adduser git
sudo su git
cd /var/lib/git/
sudo chown -R git /var/lib/git/
mkdir testing.git 
cd testing.git
git init --bare
git clone git@34.235.167.9:/var/lib/git/fhb-frontend-beta.git

cd /home/git
mkdir .ssh
cd .ssh
vim authorized_keys
echo "your-copied-public-key" >> ~/.ssh/authorized_keys

cd /var/lib/git/testing.git/objects (git log ki commit id ka separate folder aye ga)



Setup Hook

go to the /var/lib/git/fhb-frontend-beta.git/hooks
create post-receive
chmod +x post-receive

#!/bin/bash

LOGFILE="/tmp/git-post-receive.log"
echo "Post-receive hook triggered at $(date)" >> $LOGFILE

# Set working directory where the code should be checked out
WORK_DIR="/home/git/fhb-frontend"

# Checkout the code into the working directory
echo "Checking out code to $WORK_DIR" >> $LOGFILE
if [ ! -d "$WORK_DIR" ]; then
    mkdir -p "$WORK_DIR" >> $LOGFILE 2>&1
fi

GIT_WORK_TREE="$WORK_DIR" git checkout -f master >> $LOGFILE 2>&1

# Move to the working directory
echo "Changing to $WORK_DIR" >> $LOGFILE
cd "$WORK_DIR" || exit 1 >> $LOGFILE 2>&1

echo "Post-receive hook completed at $(date)" >> $LOGFILE


######################################## How i Backup and restore database volume #######################################
Backup volume:
docker run --rm -v database_mysql_data_volume_live:/volume -v $(pwd):/backup alpine tar czf /backup/mysql_backup.tar.gz -C /volume .


Restore Database volume

docker run --rm -v database_mysql_data_volume_live:/var/lib/mysql -v /home/ubuntu:/backup alpine sh -c "tar xzf /backup/mysql_backup.tar.gz -C /var/lib/mysql"

docker inspect volumename(for e.g database_mysql_data_volume_live)

Now,paste the volume link(for e.g /var/lib/docker/volumes/database_mysql_data_volume_live/_data)


version: '3.8'

services:
  mysql:
    image: mysql:latest
    container_name: my-mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: stockboombeta
    volumes:
      - /var/lib/docker/volumes/database_mysql_data_volume_live/_data:/var/lib/mysql
    ports:
      - "3307:3306"

  phpmyadmin:
    image: phpmyadmin/phpmyadmin:latest
    container_name: dev-phpmyadmin
    restart: always
    environment:
      PMA_HOST: mysql
      PMA_PORT: 3306
    ports:
      - "7098:80"
    depends_on:
      - mysql


########################################################################################################################################

Github self hosted runner:

https://youtu.be/3jXtTSnA8zw

# Create a folder
mkdir actions-runner && cd actions-runner


# Download the latest runner package
curl -o actions-runner-linux-x64-2.321.0.tar.gz -L https://github.com/actions/runner/releases/download/v2.321.0/actions-runner-linux-x64-2.321.0.tar.gz


# Optional: Validate the hash
echo "ba46ba7ce3a4d7236b16fbe44419fb453bc08f866b24f04d549ec89f1722a29e  actions-runner-linux-x64-2.321.0.tar.gz" | shasum -a 256 -c


# Extract the installer
tar xzf ./actions-runner-linux-x64-2.321.0.tar.gz

# Create the runner and start the configuration experience
./config.sh --url https://github.com/shakeebanwar/collubi-backend --token ALIPNPW5RTIFCHOVUBTVUXTHP6QBU

# Last step, run it!
./run.sh

After GitHub all commands is running successfully


Go to runner folder in your instance:

sudo ./svc.sh install
sudo ./svc.sh start

* if you are facing any permissin related issues so run runner as a root user but this approach is not recommended

ls /etc/systemd/system | grep actions.runner

The command ls /etc/systemd/system | grep actions.runner is used to:

    List Files in the Directory:
    The ls /etc/systemd/system part lists all files and directories in the /etc/systemd/system directory, which typically contains service files for systemd.

    Filter Results Using grep:
    The grep actions.runner part filters the output of ls to show only those files or directories whose names contain the text actions.runner.


sudo vim /etc/systemd/system/actions.runner.Mhd-Hsyn-Collubi.ip-172-31-15-118.service (open this file and change user to root user)
sudo systemctl daemon-reload
sudo systemctl restart actions.runner.Mhd-Hsyn-Collubi.ip-172-31-15-118.service
sudo systemctl status actions.runner.Mhd-Hsyn-Collubi.ip-172-31-15-118.service
ps -o user= -p 1557  (Main PID:)
 


example github action file:

name: CI Pipeline
on:
  push:
    branches:
      - beta-testing

jobs:
  build:
    runs-on: self-hosted

    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Create .env file
      run: |
        sudo sh -c 'echo "DJANGO_SECRET_KEY=${{ secrets.DJANGO_SECRET_KEY }}" > .env'
        sudo sh -c 'echo "DJANGO_ALLOWED_HOSTS=${{ secrets.DJANGO_ALLOWED_HOSTS }}" >> .env'
        sudo sh -c 'echo "DB_NAME=${{ secrets.DB_NAME }}" >> .env'
        sudo sh -c 'echo "DB_USER=${{ secrets.DB_USER }}" >> .env'
        sudo sh -c 'echo "DB_PASSWORD=${{ secrets.DB_PASSWORD }}" >> .env'
        sudo sh -c 'echo "DB_HOST=${{ secrets.DB_HOST }}" >> .env'
        sudo sh -c 'echo "USER_JWT_KEY=${{ secrets.USER_JWT_KEY }}" >> .env'
        sudo sh -c 'echo "SUPERADMIN_JWT_KEY=${{ secrets.SUPERADMIN_JWT_KEY }}" >> .env'

    - name: Build and Run Docker compose
      run: |
        sudo docker compose down
        sudo docker compose up --build -d

######################################################### How to Resize ROOT EBS Volume ###############################
https://www.youtube.com/watch?v=a2MTjl3KAdA




#################################### How to use tmux ###############################
sudo apt install tmux  # if not installed
tmux new -s django
python manage.py runserver 0.0.0.0:8000


To detach: Ctrl + B, then press D

To resume: tmux attach -t django



#### How to run specific script using crontab ############################

project location:
/hnh/mwp-automation


environment activate command:
source venv/bin/activate


Run script:

python main.py


0 */6 * * * cd /hnh/mwp-automation && /bin/bash -c 'source venv/bin/activate && python main.py' >> /hnh/mwp-automation/cron.log 2>&1




## How to create tunnel for creating mysql
tunnel:
ssh -i scopium-beta.pem -L 3306:beta-database.cn6s6cymwrxqdd.us-east-2.rds.amazonaws.com:3306 ubuntu@3.14.18.251

mysql -h 127.0.0.1 -P 3306 -u admin -p


Database commands:

1.Total Databases------>SHOW DATABASES;
2.Specific Database switch-----> USE databasename;
3.Show Database tables----->SHOW TABLES;


################################### AWS Systems Manager.


sudo systemctl status amazon-ssm-agent
sudo snap restart amazon-ssm-agent



















